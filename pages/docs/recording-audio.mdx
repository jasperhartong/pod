import Link from "next/link";
import AppContainer from "@/components/app-container";
import { LoopingAudioRecorderButton } from "@/components/docs/looping-audio-recorder-button";
import { LoopingAudioRecorderVisualizer } from "@/components/docs/looping-audio-recorder-visualizer";
import { AudioRecorderDemo }  from "@/components/docs/audio-recorder-demo";


<AppContainer maxWidth="sm"><div className="docs-page">

üìì <Link href={"/docs"} as={"/docs"}>Back to overview</Link>

-----

# Recording Audio with React

After wrapping up a simple page to listen to a collection of audio (using the easy-to-use lib [ReactPlayer](https://github.com/CookPete/react-player)), the time came to add some audio recording capabilities to the app. How hard could it be?

Well, quite hard and v√©ry frustrating, as Chrome, Safari and Firefox all have inconsistent Web Audio API's and recording behavior.

But, before diving into the implementation and takeaways...

## It's demo time!

<AudioRecorderDemo />

The button design might look slightly familiar, as it's a reimplementation from the [Apple¬© Voice Memos app](https://support.apple.com/en-us/HT206775) üòá.

## The recording button component



The button component is completely decoupled from the recording logic (which is capsulized in a Hook, more on that later) and only needs to be provided with 4 simple props.

```tsx
interface Props {
  isRecording: boolean;
  isRequestingAccess: boolean;
  onStartRecording: () => void;
  onStopRecording: () => void;
}
```
<sub style={{marginTop: -14, paddingRight: 4, display: "block", background: "#1e1e1e", textAlign: "right"}}>

[audio-recorder-button.tsx#L66-L71](https://github.com/jasperhartong/pod/blob/master/src/components/audio-recorder-hook/audio-recorder-button.tsx#L66-L71)

</sub>

Internally it can be in 3 different states, each with their own visual representation: `idle`, `requestingAccess` and `recording`:

<LoopingAudioRecorderButton states={["idle", "requestingAccess", "idle", "recording"]} />


#### Main Takeaways

* The `AudioRecorderButton` is based on the [ButtonBase of Material-UI](https://material-ui.com/api/button-base/). This ensures it correctly handles the easily overlooked basics of a button (e.g. focusability, accesability). This is stuff that I don't try to built completely from scratch, as it's easy to get wrong.
* The styling of the three different states is based by only changing a single className on the root of the component. This keeps the component clean, but does require some [magic "$" syntax in CSS-in-JS](https://cssinjs.org/jss-plugin-nested?v=v10.4.0#use-rulename-to-reference-a-local-rule-within-the-same-style-sheet) to reference nested classes. 

## The audio visualizer

<LoopingAudioRecorderVisualizer />


```tsx
<AudioRecorderVisualizer
    uniqueId="demo"
    getFrequencyData={getFrequencyData}
/>
```


## Implementation details

### A React Hook abstracting away audio recording controls

```tsx
const {
    isListening,
    isRecording,
    isRequestingAccess,
    startListening,
    stopListening,
    startRecording,
    stopRecording,
    getFrequencyData,
    dataBlobs,
    dataSize,
    dataSeconds,
    clearData,
    error,
  } = useAudioRecorder();
```

### ‚ö†Ô∏è MediaRecorder required a polyfill

* The API of `window.MediaRecorder` is not implemented consistent accross browsers, so it's best to use the `audio-recorder-polyfill`.
* I't also smart to rely on a polyfilled MP3 encoder, this also eases uploading and listening back the recording afterwards.

```js
import AudioRecorder from "audio-recorder-polyfill";
import mpegEncoder from "audio-recorder-polyfill/mpeg-encoder";

AudioRecorder.encoder = mpegEncoder;
AudioRecorder.prototype.mimeType = "audio/mpeg";
window.MediaRecorder = AudioRecorder;
```

* **Next.js specific**: save the above polyfill declaration into a file, e.g. `./src/client-polyfills.js` and load it within the `next.config.js`:

```js
module.exports = {
  webpack: function (cfg) {
    const originalEntry = cfg.entry;
    cfg.entry = async () => {
      const entries = await originalEntry();
      // Add client polyfills
      if (
        entries["main.js"] &&
        !entries["main.js"].includes("./src/client-polyfills.js")
      ) {
        entries["main.js"].unshift("./src/client-polyfills.js");
      }

      return entries;
    };

    return cfg;
  },
};
```

### ‚ö†Ô∏è AudioContext required standardization

* AudioContext is also not consistently implemented, so `useAudioRecorder` uses `standardized-audio-context`.

```ts
import {
  AudioContext,
  IAudioContext,
  IMediaStreamAudioSourceNode,
} from "standardized-audio-context";
```

</div></AppContainer>