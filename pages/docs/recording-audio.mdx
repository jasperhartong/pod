import { Duration } from "luxon";
import useAudioRecorder from "@/hooks/useAudioRecorder";
import { AudioRecorderButton } from "@/components/audio-recorder-hook/audio-recorder-button";
import { AudioRecorderVisualizer } from "@/components/audio-recorder-hook/audio-recorder-visualizer";
import AppContainer from "@/components/app-container";
import Link from "next/link";

<!-- DEMO CODE -->

export const AudioRecorderDemo = () => {
    const {
    isRecording,
    isRequestingAccess,
    startRecording,
    stopRecording,
    dataBlobs,
    dataSeconds,
    clearData,
    getFrequencyData
  } = useAudioRecorder();
  return (
      <div style={{display: "flex", flexDirection:"column", alignItems: "center", padding: 32}}>
        <AudioRecorderButton
            onStartRecording={() => {clearData(); startRecording()}}
            onStopRecording={stopRecording}
            isRecording={isRecording}
            isRequestingAccess={isRequestingAccess}
        />
        <div style={{margin: 16}}>
            {Duration.fromObject({
                seconds: dataSeconds,
            }).toFormat("mm:ss")}
        </div>
        {dataBlobs.length === 0 && !isRecording && ( <code>Yes, you can press that button üëÜ</code>)}
        { isRecording && <>
          <AudioRecorderVisualizer
            uniqueId="demo"
            getFrequencyData={getFrequencyData}
          />
          <p>Make some noise now! üòÅ</p>
          </>
        }
        {dataBlobs.length === 1 && ( <audio src={URL.createObjectURL(dataBlobs[0])} controls></audio>)}
        {dataBlobs.length === 1 && ( <button onClick={clearData}>Clear recording</button>)}
    </div>
  )
}

export const AudioRecorderVisualizerWithState = () => {
  const { getFrequencyData, startListening, stopListening, isListening } = useAudioRecorder();
  return (
    <div style={{display: "flex", flexDirection:"column", alignItems: "center", padding: 16}}> 
      { isListening && <>
        <AudioRecorderVisualizer
          uniqueId="demo"
          getFrequencyData={getFrequencyData}
        />
        <p>Make some noise now! üòÅ</p>
        </>
      }
    
      
    {isListening
        ? <button onClick={stopListening}>Stop listening and hide visualizer</button>
        : <button onClick={startListening}>Click to start listening and show visualizer</button>}
    </div>
  );
}

<!-- END DEMO CODE -->

<AppContainer maxWidth="sm"><div className="docs-page">

üìì <Link href={"/docs"} as={"/docs"}>Back to overview</Link>

-----

# Recording Audio with React

After wrapping up a simple page to listen to a collection of audio (using the easy-to-use lib [ReactPlayer](https://github.com/CookPete/react-player)), the time came to add some audio recording capabilities to the app. How hard could it be?

Well, quite hard and v√©ry frustrating, as Chrome, Safari and Firefox all have inconsistent Web Audio API's and recording behavior.

But, before diving into the implementation and takeaways...

## It's demo time!

<AudioRecorderDemo />

The button design might look slightly familiar, as it's a reimplementation from the [Apple¬© Voice Memos app](https://support.apple.com/en-us/HT206775) üòá.

## The recording button component



The button component is completely decoupled from the recording logic (which is capsulized in a Hook, more on that later) and only needs to be provided with 4 simple props.

```tsx
interface Props {
  isRecording: boolean;
  isRequestingAccess: boolean;
  onStartRecording: () => void;
  onStopRecording: () => void;
}
```
<sub style={{marginTop: -14, paddingRight: 4, display: "block", background: "#1e1e1e", textAlign: "right"}}>

[audio-recorder-button.tsx#L66-L71](https://github.com/jasperhartong/pod/blob/master/src/components/audio-recorder-hook/audio-recorder-button.tsx#L66-L71)

</sub>

Internally it can be in 3 different states, each with their own visual representation: `idle`, `requestingAccess` and `recording`.

<div style={{ display: "flex", justifyContent: "space-around", padding: 24 }}>
<AudioRecorderButton
    onStartRecording={() => {}}
    onStopRecording={() => {}}
    isRecording={false}
    isRequestingAccess={false} />

<AudioRecorderButton
    onStartRecording={() => {}}
    onStopRecording={() => {}}
    isRecording={false}
    isRequestingAccess={true} />

<AudioRecorderButton
    onStartRecording={() => {}}
    onStopRecording={() => {}}
    isRecording={true}
    isRequestingAccess={false} />
</div>




#### Main Takeaways

* The `AudioRecorderButton` is based on the [ButtonBase of Material-UI](https://material-ui.com/api/button-base/). This ensures it correctly handles the easily overlooked basics of a button (e.g. focusability, accesability). This is stuff that I don't try to built completely from scratch, as it's easy to get wrong.
* The styling of the three different states is based by only changing a single className on the root of the component. This keeps the component clean, but does require some [magic "$" syntax in CSS-in-JS](https://cssinjs.org/jss-plugin-nested?v=v10.4.0#use-rulename-to-reference-a-local-rule-within-the-same-style-sheet) to reference nested classes. 

## The audio visualizer

<AudioRecorderVisualizerWithState />


```tsx
<AudioRecorderVisualizer
    uniqueId="demo"
    getFrequencyData={getFrequencyData}
/>
```


## Implementation details

### A React Hook abstracting away audio recording controls

```tsx
const {
    isListening,
    isRecording,
    isRequestingAccess,
    startListening,
    stopListening,
    startRecording,
    stopRecording,
    getFrequencyData,
    dataBlobs,
    dataSize,
    dataSeconds,
    clearData,
    error,
  } = useAudioRecorder();
```

### ‚ö†Ô∏è MediaRecorder required a polyfill

* The API of `window.MediaRecorder` is not implemented consistent accross browsers, so it's best to use the `audio-recorder-polyfill`.
* I't also smart to rely on a polyfilled MP3 encoder, this also eases uploading and listening back the recording afterwards.

```js
import AudioRecorder from "audio-recorder-polyfill";
import mpegEncoder from "audio-recorder-polyfill/mpeg-encoder";

AudioRecorder.encoder = mpegEncoder;
AudioRecorder.prototype.mimeType = "audio/mpeg";
window.MediaRecorder = AudioRecorder;
```

* **Next.js specific**: save the above polyfill declaration into a file, e.g. `./src/client-polyfills.js` and load it within the `next.config.js`:

```js
module.exports = {
  webpack: function (cfg) {
    const originalEntry = cfg.entry;
    cfg.entry = async () => {
      const entries = await originalEntry();
      // Add client polyfills
      if (
        entries["main.js"] &&
        !entries["main.js"].includes("./src/client-polyfills.js")
      ) {
        entries["main.js"].unshift("./src/client-polyfills.js");
      }

      return entries;
    };

    return cfg;
  },
};
```

### ‚ö†Ô∏è AudioContext required standardization

* AudioContext is also not consistently implemented, so `useAudioRecorder` uses `standardized-audio-context`.

```ts
import {
  AudioContext,
  IAudioContext,
  IMediaStreamAudioSourceNode,
} from "standardized-audio-context";
```

</div></AppContainer>